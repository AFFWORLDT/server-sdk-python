# This file was auto-generated by Fern from our API Definition.

from __future__ import annotations
from ...core.pydantic_utilities import UniversalBaseModel
import typing
from ...types.open_ai_message import OpenAiMessage
from ...types.anyscale_model_tools_item import AnyscaleModelToolsItem
import typing_extensions
from ...core.serialization import FieldMetadata
from ...types.knowledge_base import KnowledgeBase
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import pydantic
from ...types.anthropic_model_tools_item import AnthropicModelToolsItem
from ...types.anthropic_model_model import AnthropicModelModel
from ...types.custom_llm_model_tools_item import CustomLlmModelToolsItem
from ...types.custom_llm_model_metadata_send_mode import CustomLlmModelMetadataSendMode
from ...types.deep_infra_model_tools_item import DeepInfraModelToolsItem
from ...types.groq_model_tools_item import GroqModelToolsItem
from ...types.groq_model_model import GroqModelModel
from ...types.open_ai_model_tools_item import OpenAiModelToolsItem
from ...types.open_ai_model_model import OpenAiModelModel
from ...types.open_ai_model_fallback_models_item import OpenAiModelFallbackModelsItem
from ...types.open_router_model_tools_item import OpenRouterModelToolsItem
from ...types.perplexity_ai_model_tools_item import PerplexityAiModelToolsItem
from ...types.together_ai_model_tools_item import TogetherAiModelToolsItem
from ...types.callback_step import CallbackStep
from ...types.create_workflow_block_dto import CreateWorkflowBlockDto
from ...types.handoff_step import HandoffStep
from ...types.vapi_model_tools_item import VapiModelToolsItem
from ...types.vapi_model_steps_item import VapiModelStepsItem
from ...core.pydantic_utilities import update_forward_refs


class UpdateAssistantDtoModel_Anyscale(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["anyscale"] = "anyscale"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[AnyscaleModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    model: str
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class UpdateAssistantDtoModel_Anthropic(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["anthropic"] = "anthropic"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[AnthropicModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    model: AnthropicModelModel
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class UpdateAssistantDtoModel_CustomLlm(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["custom-llm"] = "custom-llm"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[CustomLlmModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    metadata_send_mode: typing_extensions.Annotated[
        typing.Optional[CustomLlmModelMetadataSendMode], FieldMetadata(alias="metadataSendMode")
    ] = None
    url: str
    model: str
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class UpdateAssistantDtoModel_Deepinfra(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["deepinfra"] = "deepinfra"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[DeepInfraModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    model: str
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class UpdateAssistantDtoModel_Groq(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["groq"] = "groq"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[GroqModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    model: GroqModelModel
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class UpdateAssistantDtoModel_Openai(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["openai"] = "openai"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[OpenAiModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    model: OpenAiModelModel
    fallback_models: typing_extensions.Annotated[
        typing.Optional[typing.List[OpenAiModelFallbackModelsItem]], FieldMetadata(alias="fallbackModels")
    ] = None
    semantic_caching_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="semanticCachingEnabled")
    ] = None
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class UpdateAssistantDtoModel_Openrouter(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["openrouter"] = "openrouter"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[OpenRouterModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    model: str
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class UpdateAssistantDtoModel_PerplexityAi(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["perplexity-ai"] = "perplexity-ai"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[PerplexityAiModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    model: str
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class UpdateAssistantDtoModel_TogetherAi(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["together-ai"] = "together-ai"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[TogetherAiModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    model: str
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class UpdateAssistantDtoModel_Vapi(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["vapi"] = "vapi"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[VapiModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    steps: typing.Optional[typing.List[VapiModelStepsItem]] = None
    model: str
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


UpdateAssistantDtoModel = typing.Union[
    UpdateAssistantDtoModel_Anyscale,
    UpdateAssistantDtoModel_Anthropic,
    UpdateAssistantDtoModel_CustomLlm,
    UpdateAssistantDtoModel_Deepinfra,
    UpdateAssistantDtoModel_Groq,
    UpdateAssistantDtoModel_Openai,
    UpdateAssistantDtoModel_Openrouter,
    UpdateAssistantDtoModel_PerplexityAi,
    UpdateAssistantDtoModel_TogetherAi,
    UpdateAssistantDtoModel_Vapi,
]
update_forward_refs(CallbackStep, UpdateAssistantDtoModel_Vapi=UpdateAssistantDtoModel_Vapi)
update_forward_refs(CreateWorkflowBlockDto, UpdateAssistantDtoModel_Vapi=UpdateAssistantDtoModel_Vapi)
update_forward_refs(HandoffStep, UpdateAssistantDtoModel_Vapi=UpdateAssistantDtoModel_Vapi)
