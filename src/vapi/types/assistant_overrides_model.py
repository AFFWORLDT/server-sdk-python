# This file was auto-generated by Fern from our API Definition.

from __future__ import annotations
from ..core.pydantic_utilities import UniversalBaseModel
import typing
from .open_ai_message import OpenAiMessage
from .anyscale_model_tools_item import AnyscaleModelToolsItem
import typing_extensions
from ..core.serialization import FieldMetadata
from .knowledge_base import KnowledgeBase
from ..core.pydantic_utilities import IS_PYDANTIC_V2
import pydantic
from .anthropic_model_tools_item import AnthropicModelToolsItem
from .anthropic_model_model import AnthropicModelModel
from .custom_llm_model_tools_item import CustomLlmModelToolsItem
from .custom_llm_model_metadata_send_mode import CustomLlmModelMetadataSendMode
from .deep_infra_model_tools_item import DeepInfraModelToolsItem
from .groq_model_tools_item import GroqModelToolsItem
from .groq_model_model import GroqModelModel
from .open_ai_model_tools_item import OpenAiModelToolsItem
from .open_ai_model_model import OpenAiModelModel
from .open_ai_model_fallback_models_item import OpenAiModelFallbackModelsItem
from .open_router_model_tools_item import OpenRouterModelToolsItem
from .perplexity_ai_model_tools_item import PerplexityAiModelToolsItem
from .together_ai_model_tools_item import TogetherAiModelToolsItem
from .callback_step import CallbackStep
from .create_workflow_block_dto import CreateWorkflowBlockDto
from .handoff_step import HandoffStep
from .vapi_model_tools_item import VapiModelToolsItem
from .vapi_model_steps_item import VapiModelStepsItem
from ..core.pydantic_utilities import update_forward_refs


class AssistantOverridesModel_Anyscale(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["anyscale"] = "anyscale"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[AnyscaleModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    model: str
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class AssistantOverridesModel_Anthropic(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["anthropic"] = "anthropic"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[AnthropicModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    model: AnthropicModelModel
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class AssistantOverridesModel_CustomLlm(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["custom-llm"] = "custom-llm"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[CustomLlmModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    metadata_send_mode: typing_extensions.Annotated[
        typing.Optional[CustomLlmModelMetadataSendMode], FieldMetadata(alias="metadataSendMode")
    ] = None
    url: str
    model: str
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class AssistantOverridesModel_Deepinfra(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["deepinfra"] = "deepinfra"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[DeepInfraModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    model: str
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class AssistantOverridesModel_Groq(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["groq"] = "groq"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[GroqModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    model: GroqModelModel
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class AssistantOverridesModel_Openai(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["openai"] = "openai"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[OpenAiModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    model: OpenAiModelModel
    fallback_models: typing_extensions.Annotated[
        typing.Optional[typing.List[OpenAiModelFallbackModelsItem]], FieldMetadata(alias="fallbackModels")
    ] = None
    semantic_caching_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="semanticCachingEnabled")
    ] = None
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class AssistantOverridesModel_Openrouter(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["openrouter"] = "openrouter"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[OpenRouterModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    model: str
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class AssistantOverridesModel_PerplexityAi(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["perplexity-ai"] = "perplexity-ai"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[PerplexityAiModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    model: str
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class AssistantOverridesModel_TogetherAi(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["together-ai"] = "together-ai"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[TogetherAiModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    model: str
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class AssistantOverridesModel_Vapi(UniversalBaseModel):
    """
    These are the options for the assistant's LLM.
    """

    provider: typing.Literal["vapi"] = "vapi"
    messages: typing.Optional[typing.List[OpenAiMessage]] = None
    tools: typing.Optional[typing.List[VapiModelToolsItem]] = None
    tool_ids: typing_extensions.Annotated[typing.Optional[typing.List[str]], FieldMetadata(alias="toolIds")] = None
    steps: typing.Optional[typing.List[VapiModelStepsItem]] = None
    model: str
    temperature: typing.Optional[float] = None
    knowledge_base: typing_extensions.Annotated[
        typing.Optional[KnowledgeBase], FieldMetadata(alias="knowledgeBase")
    ] = None
    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = None
    emotion_recognition_enabled: typing_extensions.Annotated[
        typing.Optional[bool], FieldMetadata(alias="emotionRecognitionEnabled")
    ] = None
    num_fast_turns: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="numFastTurns")] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


AssistantOverridesModel = typing.Union[
    AssistantOverridesModel_Anyscale,
    AssistantOverridesModel_Anthropic,
    AssistantOverridesModel_CustomLlm,
    AssistantOverridesModel_Deepinfra,
    AssistantOverridesModel_Groq,
    AssistantOverridesModel_Openai,
    AssistantOverridesModel_Openrouter,
    AssistantOverridesModel_PerplexityAi,
    AssistantOverridesModel_TogetherAi,
    AssistantOverridesModel_Vapi,
]
update_forward_refs(CallbackStep, AssistantOverridesModel_Vapi=AssistantOverridesModel_Vapi)
update_forward_refs(CreateWorkflowBlockDto, AssistantOverridesModel_Vapi=AssistantOverridesModel_Vapi)
update_forward_refs(HandoffStep, AssistantOverridesModel_Vapi=AssistantOverridesModel_Vapi)
